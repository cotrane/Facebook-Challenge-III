{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "compute tf-idf matrix from coocurrency matrix of train and test sets and then use tf-idf matrices to compute cosine-similarity (linear kernel) between entries in train and test set to make predictions. Exchange the predictions made using cosine similiarity for duplicates to values of train set in the end and save result in submission file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import string\n",
      "import time\n",
      "from scipy.sparse import *\n",
      "from scipy.io import mmwrite, mmread\n",
      "import csv\n",
      "from bs4 import BeautifulSoup\n",
      "from nltk.tag import brill\n",
      "from taggerfunctions import *\n",
      "from nltk.stem.wordnet import WordNetLemmatizer\n",
      "from nltk.corpus import wordnet\n",
      "from ast import literal_eval\n",
      "import sklearn as sk\n",
      "import gc\n",
      "import os\n",
      "import psutil"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getRealDict(fname):\n",
      "    dictWords = {}\n",
      "    with open(fname, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        dictWords = {literal_eval(rows[0]):rows[1] for rows in reader}\n",
      "    return dictWords\n",
      "\n",
      "def getDict(fname):\n",
      "    dictWords = {}\n",
      "    with open(fname, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        dictWords = {rows[0]:literal_eval(rows[1]) for rows in reader}\n",
      "    return pd.Series(dictWords)\n",
      "\n",
      "def getInvDict(fname):\n",
      "    dictWords = {}\n",
      "    with open(fname, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        invDictWords = {literal_eval(rows[0]):rows[1] for rows in reader}\n",
      "    return pd.Series(invDictWords)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_results(predictions, filename):\n",
      "   \"\"\"Given a vector of predictions, save results in CSV format.\"\"\"\n",
      "   with open(filename, 'w') as f:\n",
      "       f.write(\"Id,Tags\\n\")\n",
      "       for i, pred in predictions.iteritems():\n",
      "           f.write(str(i) + \",\\\"\" + pred + \"\\\"\" + \"\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "compute tf-idf matrix for train set:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfTransformer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coocMatTitle_coo = mmread(\"coocMatTitleNew_coo.mtx\")\n",
      "coocMatTitle_csr = coocMatTitle_coo.tocsr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coocMatBodyFull_csr = mmread(\"coocMatBodyFull2_csr.mtx\")\n",
      "coocMatBodyFull_csr = coocMatBodyFull_csr.tocsr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<42048x66586 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 56489281 stored elements in COOrdinate format>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = TfidfTransformer(norm=\"l2\")\n",
      "tf_idf_matrix_title = tfidf.fit_transform(coocMatTitle_csr)\n",
      "tf_idf_matrix_body = tfidf.fit_transform(coocMatBodyFull_csr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mmwrite(\"tfidfMatTitle.mtx\",tf_idf_matrix_title)\n",
      "mmwrite(\"tfidfMatBody.mtx\",tf_idf_matrix_body)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "compute tf_idf matrix for test set:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testWTitle = mmread(\"testWordsQTitle_0-200000.mtx\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testWTitle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "<200000x45469 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 1020998 stored elements in COOrdinate format>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf_idf_matTestTitle = tfidf.fit_transform(testWTitle)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf_idf_matTestTitle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "<200000x45469 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 1020998 stored elements in Compressed Sparse Row format>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "make predicitons:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics.pairwise import linear_kernel\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "tfidf = TfidfTransformer(norm=\"l2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf_idf_title = mmread(\"tfidfMatTitle.mtx\")\n",
      "tf_idf_title = tf_idf_title.tocsr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf_idf_body = mmread(\"tfidfMatBody.mtx\")\n",
      "tf_idf_body = tf_idf_body.tocsr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "save 20 most likely tags for each post"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frange = [\"0-200000\",\"200000-400000\",\"400000-600000\",\"600000-800000\",\"800000-1000000\",\"1000000-1200000\",\"1200000-1400000\",\n",
      "          \"1400000-1600000\",\"1600000-1800000\",\"1800000-2000000\",\"2000000-2013337\"]\n",
      "invDictKeys = getInvDict(\"invdictKeys.csv\")\n",
      "invDictWords = getInvDict(\"invdictWordsNew.csv\")\n",
      "result_tags = {}\n",
      "countRows = 0\n",
      "\"\"\" choose a number for chunk_size that is a divisor of the number of rows in testWordsQ; \n",
      "    otherwise the iterator will skip the last entries!\"\"\"\n",
      "chunk_size = 1000\n",
      "tStart = time.time()\n",
      "for fran in frange:\n",
      "    fname = \"invdictIdTest_\" + fran + \".csv\"\n",
      "    \"\"\" make sure that invDictIdTest is sorted!!! use getInvDict or sort dict after using getDict \"\"\"\n",
      "    invDictIdTest = getInvDict(fname)\n",
      "    fname = \"testWordsQTitle_\" + fran + \".mtx\"\n",
      "    testQTitle = mmread(fname)\n",
      "    testQTitle = testQTitle.tocsr()\n",
      "    tf_idf_matTestTitle = tfidf.fit_transform(testQTitle)\n",
      "    #fname = \"testWordsQBody_\" + fran + \".mtx\"\n",
      "    #testQBody = mmread(fname)\n",
      "    #testQBody = testQBody.tocsr()\n",
      "    #tf_idf_matTestBody = tfidf.fit_transform(testQBody)\n",
      "    for idx_chunk in xrange(len(invDictIdTest)/chunk_size):\n",
      "        cs_title = linear_kernel(tf_idf_matTestTitle[chunk_size*idx_chunk:chunk_size*(idx_chunk+1),:], tf_idf_title)\n",
      "        #cs_body = linear_kernel(tf_idf_matTestBody[chunk_size*idx_chunk:chunk_size*(idx_chunk+1),:], tf_idf_body)\n",
      "        for row_idx,row in enumerate(cs_title):\n",
      "            rel_tags = row.argsort()[:-20:-1]\n",
      "            ar = []\n",
      "            words = []       \n",
      "            for idx in testQTitle[row_idx,:].nonzero()[1]:\n",
      "                words.append(invDictWords[idx])\n",
      "            for idx in rel_tags:\n",
      "                if invDictKeys[idx] in words:\n",
      "                    ar.append(invDictKeys[idx])\n",
      "            for idx in rel_tags[0:2]:\n",
      "                if invDictKeys[idx] not in ar:\n",
      "                    ar.append(invDictKeys[idx])\n",
      "            result_tags[invDictIdTest[countRows%200000]] = \" \".join(ar)\n",
      "            countRows += 1     \n",
      "        del cs_title\n",
      "        gc.collect()\n",
      "        if countRows % 20000 == 0:\n",
      "            print(\"{0:d} questions finished in {1:.0f}s\".format(countRows, time.time()-tStart))\n",
      "            tStart = time.time()\n",
      "\"\"\" the linear_kernel below is necessary because matrix size 13337 is not divisible by chunk_size;\n",
      "    it will skip the last part in the for loop above and i have to do it manually below \"\"\"\n",
      "cs_title = linear_kernel(tf_idf_matTestTitle[len(invDictIdTest) - len(invDictIdTest)%chunk_size:,:], tf_idf_title)\n",
      "#cs_body = linear_kernel(tf_idf_matTestBody[len(invDictIdTest) - len(invDictIdTest)%chunk_size:,:], tf_idf_body)\n",
      "for row_idx,row in enumerate(cs_title):\n",
      "    rel_tags = row.argsort()[:-20:-1]\n",
      "    ar = []\n",
      "    words = []       \n",
      "    for idx in testQTitle[row_idx,:].nonzero()[1]:\n",
      "        words.append(invDictWords[idx])\n",
      "    for idx in rel_tags:\n",
      "        if invDictKeys[idx] in words:\n",
      "            ar.append(invDictKeys[idx])\n",
      "    for idx in rel_tags[0:2]:\n",
      "        if invDictKeys[idx] not in ar:\n",
      "            ar.append(invDictKeys[idx])\n",
      "    result_tags[invDictIdTest[countRows%200000]] = \" \".join(ar)\n",
      "    countRows += 1 \n",
      "\"\"\" save the resulting dict in file \"\"\"\n",
      "result_tagsSeries = pd.Series(result_tags)\n",
      "result_tagsSeries.to_csv(\"resultTags_title_v3.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "save 3 most likely tags for each post:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frange = [\"0-200000\",\"200000-400000\",\"400000-600000\",\"600000-800000\",\"800000-1000000\",\"1000000-1200000\",\"1200000-1400000\",\n",
      "          \"1400000-1600000\",\"1600000-1800000\",\"1800000-2000000\",\"2000000-2013337\"]\n",
      "invDictKeys = getInvDict(\"invdictKeys.csv\")\n",
      "result_tags = {}\n",
      "countRows = 0\n",
      "\"\"\" choose a number for chunk_size that is a divisor of the number of rows in testWordsQ; \n",
      "    otherwise the iterator will skip the last entries!\"\"\"\n",
      "chunk_size = 500\n",
      "tStart = time.time()\n",
      "for fran in frange:\n",
      "    fname = \"invdictIdTest_\" + fran + \".csv\"\n",
      "    \"\"\" make sure that invDictIdTest is sorted!!! use getInvDict or sort dict after using getDict \"\"\"\n",
      "    invDictIdTest = getInvDict(fname)\n",
      "    fname = \"testWordsQTitle_\" + fran + \".mtx\"\n",
      "    testQTitle = mmread(fname)\n",
      "    tf_idf_matTestTitle = tfidf.fit_transform(testQTitle)\n",
      "    fname = \"testWordsQBody_\" + fran + \".mtx\"\n",
      "    testQBody = mmread(fname)\n",
      "    testQBody = testQBody.tocsr()\n",
      "    tf_idf_matTestBody = tfidf.fit_transform(testQBody)\n",
      "    del testQTitle\n",
      "    del testQBody\n",
      "    gc.collect()\n",
      "    for idx_chunk in xrange(len(invDictIdTest)/chunk_size):\n",
      "        cs_title = linear_kernel(tf_idf_matTestTitle[chunk_size*idx_chunk:chunk_size*(idx_chunk+1),:], tf_idf_title)\n",
      "        cs_body = linear_kernel(tf_idf_matTestBody[chunk_size*idx_chunk:chunk_size*(idx_chunk+1),:], tf_idf_body)\n",
      "        for row in cs_title:\n",
      "            rel_tags = (row).argsort()[:-4:-1]\n",
      "            ar = []\n",
      "            for idx in rel_tags:\n",
      "                ar.append(invDictKeys[idx])\n",
      "            result_tags[invDictIdTest[countRows%200000]] = \" \".join(ar)\n",
      "            countRows += 1     \n",
      "        del cs_title\n",
      "        gc.collect()\n",
      "        if countRows % 20000 == 0:\n",
      "            print(\"{0:d} questions finished in {1:.0f}s\".format(countRows, time.time()-tStart))\n",
      "            tStart = time.time()\n",
      "\"\"\" the linear_kernel below is necessary because matrix size 13337 is not divisible by chunk_size;\n",
      "    it will skip the last part in the for loop above and i have to do it manually below \"\"\"\n",
      "cs_title = linear_kernel(tf_idf_matTestTitle[len(invDictIdTest) - len(invDictIdTest)%chunk_size:,:], tf_idf_title)\n",
      "cs_body = linear_kernel(tf_idf_matTestBody[len(invDictIdTest) - len(invDictIdTest)%chunk_size:,:], tf_idf_body)\n",
      "for lst in cs_title:\n",
      "    rel_tags = lst.argsort()[:-4:-1]\n",
      "    for key in rel_tags:\n",
      "        l.append(invDictKeys[key])\n",
      "    result_tags[invDictIdTest[countRows%200000]] = \" \".join(l)\n",
      "    countRows += 1 \n",
      "\"\"\" save the resulting dict in file \"\"\"\n",
      "result_tagsSeries = pd.Series(result_tags)\n",
      "result_tagsSeries.to_csv(\"resultTags_T+B_v2.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result_tagsSeries_1 = getRealDict(\"resultTags_T+B_v2.csv\")\n",
      "#result_tagsSeries_1 = pd.Series(result_tagsSeries_1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result_tagsSeries_2 = getRealDict(\"resultTags_T+B_v2_2.csv\")\n",
      "#result_tagsSeries_2 = pd.Series(result_tagsSeries_2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result_tagsSeries_full = dict(list(result_tagsSeries_1.items()) + list(result_tagsSeries_2.items()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result_tagsSeries_full1 = pd.Series(result_tagsSeries_full)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result_tagsSeries_full1.to_csv(\"resultTags_T+B_v2_full.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "change prediction found by cosine similarity for duplicates to values of train set:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "duplicates = pd.read_csv(\"duplicates_single_v2.csv\", index_col='Unnamed: 0')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dup = pd.Series(duplicates['Tags'].values, index=duplicates['Id_x'])\n",
      "result = getRealDict(\"resultTags_title_v3.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for key, value in dup.iteritems():\n",
      "    result[key] = value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_results(result, \"submission_tfidf_titleonly_v3.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}